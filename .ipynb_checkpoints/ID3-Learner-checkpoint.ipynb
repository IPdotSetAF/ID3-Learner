{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9657783",
   "metadata": {},
   "source": [
    "# ID3 Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9457b69b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d7f49be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "raw data : \n",
      "\n",
      "     Outlook Temperature Humidity    Wind Play Tennis\n",
      "0      Sunny         Hot     High    Weak          No\n",
      "1      Sunny         Hot     High  Strong          No\n",
      "2   Overcast         Hot     High    Weak         Yes\n",
      "3       Rain        Mild     High    Weak         Yes\n",
      "4       Rain        Cool   Normal    Weak         Yes\n",
      "5       Rain        Cool   Normal  Strong          No\n",
      "6   Overcast        Cool   Normal  Strong         Yes\n",
      "7      Sunny        Mild     High    Weak          No\n",
      "8      Sunny        Cool   Normal    Weak         Yes\n",
      "9       Rain        Mild   Normal    Weak         Yes\n",
      "10     Sunny        Mild   Normal  Strong         Yes\n",
      "11  Overcast        Mild     High  Strong         Yes\n",
      "12  Overcast         Hot   Normal    Weak         Yes\n",
      "13      Rain        Mild     High  Strong          No\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "_dataSetFileName = 'PlayTennis.csv'\n",
    "\n",
    "_features, _data, _target = ReadData(_dataSetFileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "17f58469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Entropy : 0.9402859586706311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID3{Outlook,['Overcast' 'Rain' 'Sunny'],['Yes' ID3{Wind,['Strong' 'Weak'],['No' 'Yes']}\n",
       " ID3{Humidity,['High' 'Normal'],['No' 'Yes']}]}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = ID3_Trainer(_features, _data, _target, ID3_Algorythm.INFO_GAIN)\n",
    "# trainer = ID3_Trainer(_features, _data, _target, ID3_Algorythm.INFO_GAIN)\n",
    "\n",
    "print(f'Total Entropy : {trainer.ID3.Entropy}')\n",
    "trainer.ID3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443d8a9d",
   "metadata": {},
   "source": [
    "## ID3 :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b60800",
   "metadata": {},
   "source": [
    "### Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8271a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class ID3_Algorythm(Enum) :\n",
    "    INFO_GAIN = 0\n",
    "    GAIN_RATIO = 1\n",
    "    GINI_INDEX = 2\n",
    "\n",
    "class ID3_Trainer :\n",
    "    @property\n",
    "    def ID3 (self):\n",
    "        return self.__ID3\n",
    "\n",
    "    def __init__(self, featurs, data, target, id3_Algorythm):\n",
    "        if(id3_Algorythm == ID3_Algorythm.INFO_GAIN):\n",
    "            self.__ID3 = IG_ID3()\n",
    "        elif(id3_Algorythm == ID3_Algorythm.GAIN_RATIO):\n",
    "            self.__ID3 = GR_ID3()\n",
    "        elif(id3_Algorythm == ID3_Algorythm.GINI_INDEX):\n",
    "            self.__ID3 = GI_ID3()\n",
    "        else :\n",
    "            print('invalid Algorythm')\n",
    "            return\n",
    "        \n",
    "        self.__ID3.Train(featurs, data , target)\n",
    "        \n",
    "class ID3:\n",
    "    __Name = ''\n",
    "    @property \n",
    "    def Name(self):\n",
    "        return self.__Name\n",
    "    \n",
    "    __Keys = []\n",
    "    @property \n",
    "    def Keys(self):\n",
    "        return self.__Keys\n",
    "    \n",
    "    __Values = []\n",
    "    @property \n",
    "    def Values(self):\n",
    "        return self.__Values\n",
    "    \n",
    "    __TotalEntropy = 0\n",
    "    @property \n",
    "    def Entropy(self):\n",
    "        return self.__TotalEntropy\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'ID3{\"{\"}{self.__Name},{self.__Keys},{self.__Values}{\"}\"}'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self}'\n",
    "    \n",
    "    def _CalculateEntropy(self, target):\n",
    "        totalEntries = len(target)\n",
    "        entropy = 0\n",
    "        for t in np.unique(target):\n",
    "            targetCount = np.count_nonzero(target == t)\n",
    "            targetProbability = targetCount/totalEntries\n",
    "            entropy -= targetProbability * np.log2(targetProbability)\n",
    "        return entropy\n",
    "    \n",
    "    def _SliceDataByFeatureIndex(self, data, featureIndex):\n",
    "        featureData = np.array(data)[:,featureIndex]\n",
    "        featurePossibleValues = np.unique(featureData)\n",
    "        return featureData , featurePossibleValues\n",
    "    \n",
    "    def _CalculateBestFeature(self, entropy, features, data, target):\n",
    "        pass\n",
    "    \n",
    "    def _Instantiate(self):\n",
    "        pass\n",
    "    \n",
    "    def Train(self, features, data , target):\n",
    "        self.__TotalEntropy = self._CalculateEntropy(target)\n",
    "        self.__Name, featureIndex = self._CalculateBestFeature( self.__TotalEntropy, features, data, target)\n",
    "        \n",
    "        featureData ,featurePossibleValues = self._SliceDataByFeatureIndex(data, featureIndex)\n",
    "        self.__Keys = featurePossibleValues\n",
    "        \n",
    "        newFeatures = np.delete(features, featureIndex, 0)\n",
    "        newData = np.delete(data, featureIndex, 1)\n",
    "        tmpValues = list([])\n",
    "        for value in self.__Keys:\n",
    "            valueIndecies = np.where(featureData == value)\n",
    "            newTarget = np.array(target)[valueIndecies]\n",
    "            pTargets = np.unique(newTarget)\n",
    "            if(len(pTargets) == 1):\n",
    "                tmpValues.append(pTargets[0])\n",
    "            else:\n",
    "                tmpValues.append(self._Instantiate())\n",
    "                tmpValues[-1].Train(newFeatures, np.array(newData)[valueIndecies], newTarget)\n",
    "        \n",
    "        self.__Values = np.array(tmpValues)\n",
    "    \n",
    "    def Resolve(key):\n",
    "        return self.__Values[self.__Keys.index(key)]\n",
    "    \n",
    "        \n",
    "class IG_ID3(ID3):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super()\n",
    "        \n",
    "    def _Instantiate(self):\n",
    "        return IG_ID3()\n",
    "    \n",
    "    def _CalculateBestFeature(self, entropy, features, data, target):\n",
    "        gains = np.zeros((len(features)), dtype=float)\n",
    "        for featureIndex in range(len(features)):\n",
    "            featureData ,featurePossibleValues = self._SliceDataByFeatureIndex(data, featureIndex)\n",
    "            gains[featureIndex] = entropy\n",
    "            for c in featurePossibleValues:\n",
    "                valueIndecies = np.where(featureData == c)\n",
    "                gains[featureIndex] -= (np.count_nonzero(featureData == c)/ len(data)) * self._CalculateEntropy(np.array(target)[valueIndecies])\n",
    "        \n",
    "        #print(features)\n",
    "        #print(gains)\n",
    "        featureIndex = gains.argmax()\n",
    "        return features[featureIndex], featureIndex\n",
    "    \n",
    "class GR_ID3(ID3):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super()\n",
    "        \n",
    "    def _Instantiate(self):\n",
    "        return GR_ID3()\n",
    "    \n",
    "    def _CalculateBestFeature(self, entropy, features, data, target):\n",
    "        gains = np.zeros((len(features)), dtype=float)\n",
    "        for featureIndex in range(len(features)):\n",
    "            featureData ,featurePossibleValues = self._SliceDataByFeatureIndex(data, featureIndex)\n",
    "            for c in featurePossibleValues:\n",
    "                valueIndecies = np.where(featureData == c)\n",
    "                gains[featureIndex] -= (np.count_nonzero(featureData == c)/ len(data)) * self._CalculateEntropy(np.array(target)[valueIndecies])\n",
    "            gains[featureIndex] = (entropy + gains[featureIndex])/gains[featureIndex]\n",
    "        #print(features)\n",
    "        #print(gains)\n",
    "        featureIndex = gains.argmax()\n",
    "        return features[featureIndex], featureIndex\n",
    "  \n",
    "\n",
    "class GI_ID3(ID3):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super()\n",
    "        \n",
    "    def _Instantiate(self):\n",
    "        return GI_ID3()\n",
    "    \n",
    "    def __CalculateGINI(self, target):\n",
    "        totalEntries = len(target)\n",
    "        gini = 1\n",
    "        for t in np.unique(target):\n",
    "            targetCount = np.count_nonzero(target == t)\n",
    "            targetProbability = targetCount/totalEntries\n",
    "            gini -= targetProbability * targetProbability\n",
    "        return gini\n",
    "    \n",
    "    #TODO: calculate gini index\n",
    "    def _CalculateBestFeature(self, entropy, features, data, target):\n",
    "        ginis = np.zeros((len(features)), dtype=float)\n",
    "        for featureIndex in range(len(features)):\n",
    "            featureData ,featurePossibleValues = self._SliceDataByFeatureIndex(data, featureIndex)\n",
    "            for c in featurePossibleValues:\n",
    "                valueIndecies = np.where(featureData == c)\n",
    "                ginis[featureIndex] += (np.count_nonzero(featureData == c)/ len(data)) * self.__CalculateGINI(np.array(target)[valueIndecies])\n",
    "        #print(features)\n",
    "        #print(gains)\n",
    "        featureIndex = ginis.argmin()\n",
    "        return features[featureIndex], featureIndex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5820376c",
   "metadata": {},
   "source": [
    "## Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "23cac299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "def ReadData(fileName):\n",
    "    rawData = read_csv(fileName)\n",
    "    print(f'\\nraw data : \\n\\n{rawData}')\n",
    "\n",
    "    columns = np.array(rawData.columns)[:-1]\n",
    "    #print(f'\\ncolumns are : {columns}')\n",
    "    \n",
    "    data = np.array(rawData)[:,:-1]\n",
    "    #print(f'\\nfeatures are : \\n{data}')\n",
    "\n",
    "    target = np.array(rawData)[:,-1]\n",
    "    #print(f'\\ntarget is : {target}')\n",
    "    \n",
    "    return columns, data, target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
